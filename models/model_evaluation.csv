,svm_report,nb_report
collaboration,"{'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35.0}","{'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35.0}"
sales_inquiry,"{'precision': 1.0, 'recall': 0.9534883720930233, 'f1-score': 0.9761904761904762, 'support': 43.0}","{'precision': 1.0, 'recall': 0.9534883720930233, 'f1-score': 0.9761904761904762, 'support': 43.0}"
spam_ad,"{'precision': 0.9574468085106383, 'recall': 1.0, 'f1-score': 0.9782608695652174, 'support': 45.0}","{'precision': 0.9574468085106383, 'recall': 1.0, 'f1-score': 0.9782608695652174, 'support': 45.0}"
support_complaint,"{'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37.0}","{'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37.0}"
accuracy,0.9875,0.9875
macro avg,"{'precision': 0.9893617021276596, 'recall': 0.9883720930232558, 'f1-score': 0.9886128364389234, 'support': 160.0}","{'precision': 0.9893617021276596, 'recall': 0.9883720930232558, 'f1-score': 0.9886128364389234, 'support': 160.0}"
weighted avg,"{'precision': 0.988031914893617, 'recall': 0.9875, 'f1-score': 0.9874870600414078, 'support': 160.0}","{'precision': 0.988031914893617, 'recall': 0.9875, 'f1-score': 0.9874870600414078, 'support': 160.0}"
